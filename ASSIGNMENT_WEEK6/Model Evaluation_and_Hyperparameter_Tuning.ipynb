{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fdd7858-0f21-46ed-a7f6-b47cecaa9310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d54fe865-4da4-4797-9b19-c73edc05f907",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"model\": LogisticRegression(max_iter=1000),\n",
    "        \"params\": {\n",
    "            \"C\": [0.01, 0.1, 1, 10],\n",
    "            \"solver\": ['liblinear', 'lbfgs']\n",
    "        }\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"model\": RandomForestClassifier(),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [50, 100, 150],\n",
    "            \"max_depth\": [None, 5, 10]\n",
    "        }\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        \"model\": SVC(),\n",
    "        \"params\": {\n",
    "            \"C\": [0.1, 1, 10],\n",
    "            \"kernel\": ['linear', 'rbf']\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ae42f5c-a795-4aa2-82a4-236024bf1c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Tuning Logistic Regression...\n",
      "\n",
      "üîç Tuning Random Forest...\n",
      "\n",
      "üîç Tuning SVM...\n",
      "\n",
      " Model Comparison:\n",
      "\n",
      "                 Model                              Best Params  Accuracy  \\\n",
      "0  Logistic Regression         {'C': 10, 'solver': 'liblinear'}  0.956140   \n",
      "1        Random Forest  {'max_depth': None, 'n_estimators': 50}  0.964912   \n",
      "2                  SVM             {'C': 1, 'kernel': 'linear'}  0.956140   \n",
      "\n",
      "   Precision    Recall  F1-Score  \n",
      "0   0.945946  0.985915  0.965517  \n",
      "1   0.958904  0.985915  0.972222  \n",
      "2   0.945946  0.985915  0.965517  \n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for name, config in models.items():\n",
    "    print(f\"\\nüîç Tuning {name}...\")\n",
    "    grid = GridSearchCV(config[\"model\"], config[\"params\"], cv=5, scoring='accuracy')\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Best Params\": grid.best_params_,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1-Score\": f1_score(y_test, y_pred)\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\n Model Comparison:\\n\")\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be547f1f-1c25-47f2-acd6-bbafd3519583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model Based on F1-Score:\n",
      "Model                                     Random Forest\n",
      "Best Params    {'max_depth': None, 'n_estimators': 100}\n",
      "Accuracy                                       0.964912\n",
      "Precision                                      0.958904\n",
      "Recall                                         0.985915\n",
      "F1-Score                                       0.972222\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "best_model_idx = df_results['F1-Score'].idxmax()\n",
    "print(\"\\nBest Model Based on F1-Score:\")\n",
    "print(df_results.loc[best_model_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d408fb-d2cc-4de0-86cd-b084c1e3cb08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
